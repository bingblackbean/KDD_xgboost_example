{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_xgboost_nsl_kdd.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1uWYBYhmwMwjXrrCuUDUEI2B_sPqvqavZ",
      "authorship_tag": "ABX9TyPROm2TxOBdbyAESXbNRcV3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bingblackbean/test_nls_kdd/blob/master/test_xgboost_nsl_kdd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQvCM03OpebN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from imblearn.over_sampling import SMOTE, ADASYN,BorderlineSMOTE,SVMSMOTE\n",
        "from imblearn.combine import SMOTEENN, SMOTETomek\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma3xRppwq9b5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data():\n",
        "    field_names_df = pd.read_csv(field_name_file,header=None,names=['name','data_type'])\n",
        "    field_names = field_names_df['name'].tolist()\n",
        "    field_names+=['label', 'label_code']\n",
        "    df = pd.read_csv(train_file, header=None, names=field_names)\n",
        "    df_test = pd.read_csv(test_file, header=None, names=field_names)\n",
        "    attack_type_df = pd.read_csv(attack_type_file, sep=' ',header=None, names=['name', 'attack_type'])\n",
        "    attack_type_dict = dict(zip(attack_type_df['name'].tolist(), attack_type_df['attack_type'].tolist()))\n",
        "    df.drop('label_code',axis=1,inplace=True)\n",
        "    df_test.drop('label_code',axis=1, inplace=True)\n",
        "    df['label'].replace(attack_type_dict,inplace=True)\n",
        "    df_test['label'].replace(attack_type_dict, inplace=True)\n",
        "    return df,df_test\n",
        "\n",
        "\n",
        "\n",
        "def label_encoder(data):\n",
        "    labelencoder = LabelEncoder()\n",
        "    for col in data.columns:\n",
        "        data[col] = labelencoder.fit_transform(data[col])\n",
        "    return data\n",
        "\n",
        "\n",
        "def split_category(data, columns):\n",
        "    print(data)\n",
        "    print(columns)\n",
        "    cat_data = data[columns]\n",
        "    rest_data = data.drop(columns, axis=1)\n",
        "    return rest_data, cat_data\n",
        "\n",
        "\n",
        "def one_hot_cat(data):\n",
        "    if isinstance(data, pd.Series):\n",
        "        data = pd.DataFrame(data, columns=[data.name])\n",
        "    out = pd.DataFrame([])\n",
        "    for col in data.columns:\n",
        "        one_hot_cols = pd.get_dummies(data[col], prefix=col)\n",
        "        out = pd.concat([out, one_hot_cols], axis=1)\n",
        "    out.set_index(data.index)\n",
        "    return out\n",
        "\n",
        "def log_transform(data,log_cols):\n",
        "    for col in log_cols:\n",
        "        data[col] = np.log(data[col]+1) # add 1 to avoid log 0\n",
        "    return data\n",
        "\n",
        "\n",
        "def create_feture_sel_model(X, Y):\n",
        "    model = ExtraTreesClassifier(n_estimators=250,\n",
        "                                 random_state=0)\n",
        "    model.fit(X, Y)\n",
        "    return model\n",
        "\n",
        "\n",
        "def selectKImportance(model, X, k=5):\n",
        "    return X.iloc[:, model.feature_importances_.argsort()[::-1][:k]]\n",
        "\n",
        "\n",
        "def roc_auc_score_multiclass(actual_class, pred_class, average=\"macro\"):\n",
        "\n",
        "    # creating a set of all the unique classes using the actual class list\n",
        "    unique_class = set(actual_class)\n",
        "    roc_auc_dict = {}\n",
        "    for per_class in unique_class:\n",
        "        # creating a list of all the classes except the current class\n",
        "        other_class = [x for x in unique_class if x != per_class]\n",
        "\n",
        "        # marking the current class as 1 and all other classes as 0\n",
        "        new_actual_class = [0 if x in other_class else 1 for x in actual_class]\n",
        "        new_pred_class = [0 if x in other_class else 1 for x in pred_class]\n",
        "\n",
        "        # using the sklearn metrics method to calculate the roc_auc_score\n",
        "        roc_auc = roc_auc_score(\n",
        "            new_actual_class,\n",
        "            new_pred_class,\n",
        "            average=average)\n",
        "        roc_auc_dict[per_class] = roc_auc\n",
        "    return roc_auc_dict\n",
        "\n",
        "\n",
        "# oversampling\n",
        "def resample_method(X, Y, method='SMOTE'):\n",
        "    if method == 'SMOTE':\n",
        "        oversample = SMOTE()\n",
        "        X, Y = oversample.fit_resample(X, Y)\n",
        "        return X, Y\n",
        "    elif method == 'SMOTE_NUM':\n",
        "        oversample = SMOTE(sampling_strategy='minority')\n",
        "        X, Y = oversample.fit_resample(X, Y)\n",
        "        return X, Y\n",
        "    elif method == 'BorderlineSMOTE':\n",
        "        oversample = BorderlineSMOTE()\n",
        "        X, Y = oversample.fit_resample(X, Y)\n",
        "        return X, Y\n",
        "    elif method == 'SVMSMOTE':\n",
        "        oversample = SVMSMOTE()\n",
        "        X, Y = oversample.fit_resample(X, Y)\n",
        "        return X, Y\n",
        "    elif method == 'ADASYN':\n",
        "        oversample = ADASYN(sampling_strategy='all')\n",
        "        X, Y = oversample.fit_resample(X, Y)\n",
        "        return X, Y\n",
        "    elif method == 'SMOTEENN':\n",
        "        oversample = SMOTEENN()\n",
        "        X, Y = oversample.fit_resample(X, Y)\n",
        "        return X, Y\n",
        "    elif method == 'SMOTETomek':\n",
        "        oversample = SMOTETomek()\n",
        "        X, Y = oversample.fit_resample(X, Y)\n",
        "        return X, Y\n",
        "    else:\n",
        "        return X, Y\n",
        "\n",
        "\n",
        "\n",
        "def pipe_line(\n",
        "        add_catgory=False,\n",
        "        resampling='SMOTETomek',\n",
        "        top_k=38,\n",
        "        class_w=None):\n",
        "    # read data form csv\n",
        "    df,df_test = read_data()\n",
        "    c = Counter(df['label'])\n",
        "    print(f'original df label is {c}')\n",
        "    c = Counter(df_test['label'])\n",
        "    print(f'original df_test label is {c}')\n",
        "\n",
        "    # split data to X and Y\n",
        "    Y = df['label']\n",
        "    Y_test = df_test['label']\n",
        "    X = df.drop('label', axis=1)\n",
        "    X_test = df_test.drop('label', axis=1)\n",
        "\n",
        "\n",
        "\n",
        "    # log transform data\n",
        "    log_cols = ['src_bytes','dst_bytes']\n",
        "    X = log_transform(X,log_cols)\n",
        "    X_test = log_transform(X_test,log_cols)\n",
        "    print('log transform large data')\n",
        "\n",
        "    # categorical_columns\n",
        "    categorical_columns = ['protocol_type', 'service', 'flag']\n",
        "\n",
        "    # first label_encoder to allow resampling\n",
        "    X[categorical_columns] = label_encoder(X[categorical_columns])\n",
        "    X_test[categorical_columns] = label_encoder(X_test[categorical_columns])\n",
        "\n",
        "\n",
        "\n",
        "    # resampling data\n",
        "    X, Y = resample_method(X, Y, method=resampling)\n",
        "    X, X_cat = split_category(X, categorical_columns)\n",
        "    X_test, X_test_cat = split_category(X_test, categorical_columns)\n",
        "    c = Counter(Y)\n",
        "    print(f'after oversampling df label is {c}')\n",
        "    c = Counter(Y_test)\n",
        "    print(f'after oversampling df label is {c}')\n",
        "    # feature selecting\n",
        "    if top_k is not None:\n",
        "        feature_sel_model = create_feture_sel_model(X, Y)\n",
        "        X = selectKImportance(feature_sel_model, X, k=top_k)\n",
        "        X_test = selectKImportance(feature_sel_model, X_test, k=top_k)\n",
        "        print(f'select {top_k} features')\n",
        "    else:\n",
        "        print(f'use all features')\n",
        "    if add_catgory:\n",
        "        # convert to one-hot\n",
        "        X_cat_one_hot_cols = one_hot_cat(X_cat)\n",
        "        X_test_cat_one_hot_cols = one_hot_cat(X_test_cat)\n",
        "        # align train to test\n",
        "        X_cat_one_hot_cols, X_test_cat_one_hot_cols = X_cat_one_hot_cols.align(\n",
        "            X_test_cat_one_hot_cols, join='inner', axis=1)\n",
        "        X_cat_one_hot_cols.fillna(0, inplace=True)\n",
        "        X_test_cat_one_hot_cols.fillna(0, inplace=True)\n",
        "        X = pd.concat([X, X_cat_one_hot_cols], axis=1, ignore_index=True)\n",
        "        X_test = pd.concat([X_test, X_test_cat_one_hot_cols],\n",
        "                           axis=1, ignore_index=True)\n",
        "        print(f'add one-hot features')\n",
        "    else:\n",
        "        print(f'no one-hot features')\n",
        "\n",
        "\n",
        "    scaler = preprocessing.Normalizer().fit(X)\n",
        "    X = scaler.transform(X)\n",
        "    X_test = scaler.transform(X_test)\n",
        "    print(f'Normalize data')\n",
        "\n",
        "    Y_val = Y\n",
        "    X_val = X\n",
        "    print(f'split dataset to train and validate')\n",
        "    print(Counter(Y))\n",
        "    print(Counter(Y_val))\n",
        "    model = xgb.XGBClassifier(\n",
        "        objective='multi:softprob',\n",
        "        disable_default_eval_metric=1)\n",
        "    if class_w is None:\n",
        "        class_w = 'balanced'\n",
        "\n",
        "    sample_w = compute_sample_weight(class_weight=class_w, y=Y)\n",
        "    print(f'compute_sample_weight done')\n",
        "\n",
        "    hist = model.fit(\n",
        "        X,\n",
        "        Y,\n",
        "        eval_metric='logloss',\n",
        "        sample_weight=sample_w,\n",
        "        verbose=True,\n",
        "        # eval_set=(\n",
        "        #     X_val,\n",
        "        #     Y_val)\n",
        "    )\n",
        "    print(f'fitting done')\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    auc_score = roc_auc_score_multiclass(Y_test, y_pred)\n",
        "    print(auc_score)\n",
        "    print(f'auc score is {accuracy_score(Y_test, y_pred)}')\n",
        "    print(sklearn.metrics.confusion_matrix(Y_test, y_pred))\n",
        "    print(sklearn.metrics.classification_report(Y_test, y_pred, digits=3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTPP0eakuPzU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "aca343e4-7cdd-4498-98d8-a14a819c9253"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51xnSWrOrHpT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "d0ec4474-e8ba-4af5-e5e4-68fe7acf84db"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    import os\n",
        "    print(os.getcwd())\n",
        "    base_path = 'drive/My Drive/ML app'\n",
        "    train_file = base_path+'/KDDTrain+.csv'\n",
        "    test_file = base_path+'/KDDTest+.csv'\n",
        "    field_name_file = base_path+'/Field Names.csv'\n",
        "    attack_type_file = base_path+'/attack_types.txt'\n",
        "\n",
        "    class_w = {\n",
        "        'normal': 1,\n",
        "        'dos': 1,\n",
        "        'probe': 1,\n",
        "        'r2l': 1,\n",
        "        'u2r': 1}\n",
        "    pipe_line(add_catgory=True, resampling='ADASYN', top_k=None,class_w=class_w)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "original df label is Counter({'normal': 67343, 'dos': 45927, 'probe': 11656, 'r2l': 995, 'u2r': 52})\n",
            "original df_test label is Counter({'normal': 9710, 'dos': 7636, 'r2l': 2576, 'probe': 2421, 'u2r': 200})\n",
            "log transform large data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}